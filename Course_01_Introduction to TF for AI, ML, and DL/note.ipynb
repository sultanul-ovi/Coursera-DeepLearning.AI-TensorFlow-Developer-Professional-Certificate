{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Course\n",
    "This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning. \n",
    "\n",
    "The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllabus\n",
    "* Week 01: A New Programming Paradigm\n",
    "* Week 02: Introduction to Computer Vision\n",
    "* Week 03: Enhancing Vision with Convolutional Neural Networks\n",
    "* Week 04: Using Real-world Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A New Programming Paradigm\n",
    "\n",
    "## An Overview\n",
    "* One of the best tools we can use to implement deep learning and machine learning algorithms is TensorFlow.\n",
    "* Programming frameworks like TensorFlow, PyTorchm caffe and many others can help us in learning algorithms, moreover they can save a lot of time.\n",
    "* Deep learning and machine learning skills are becoming ever more important and opening up whole new scenarios.\n",
    "* Even though the whole world sees the promise and the hope of these machine learning AI capabilities changing so many things, the world just doesn't have enough AI developers today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Primer in Machine Learning\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-1.PNG\" alt=\"traditional-programming\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 1. Traditional Programming</i></p>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-3.PNG\" alt=\"activity-recognition\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 2. Activity Recognition using Traditional Programming</i></p>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-2.PNG\" alt=\"new-programming\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 3. New Programming</i></p>\n",
    "\n",
    "* Rules are express in a programming language and data can come from a variety of sources from local variables or the way up to databases\n",
    "* Machine learning is really similar but we only flipping the axes\n",
    "* Neural network is the workhorse of doing this type of pattern recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ‘Hello World’ of neural networks\n",
    "Machine learning is all about a computer learning the patterns that distinguish things. The simplest possible neural network is one that has only one neuron in it, we can see it the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In keras, we use Dense to define a layer of connected neurons\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) \n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype-float)\n",
    "\n",
    "# the training takes place in the fit command\n",
    "# epoch = 500, means that it will go through the training loop 500 times\n",
    "model.fit(xs, ys, epochs=500)\n",
    "\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions, **loss** and **optimizer**. \n",
    "* Loss function measure how good or how bad its guess was. Loss function is mean squarred error.\n",
    "* Optimizer function figures out the next guess, how good or how badly the guess was done using the data from the loss function. Each guess should be better than the one before. Optimizer is SGD (Stochastic Gradient Descent)\n",
    "\n",
    "In conclusion, the steps to figure out the patterns are:\n",
    "1. Make a guess\n",
    "2. Measure how good or how bad the guesses with the loss function\n",
    "3. Use the optimizer and the data to make another guess and repeat this\n",
    "\n",
    "If the result is far from expectation or what you guess before, there are 2 reasons for it.\n",
    "1. Training data is too small\n",
    "2. When using neural networks, they deal in probability as they try to figure out the answers for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Rules to Data\n",
    "* Traditional paradigm of expressing rules in a coding language may not always work to solve a problem. Computer vision are very difficult to solve with rules-based programming.\n",
    "* We can feed a computer with enough data that we describe / label as what we want it to recognize. Example: fitting numbers to a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "\n",
    "Computer vision is the field of having a computer understand and label what is present in an image. Can you figure out how can we tell the computer to recognize fashion image? Yes, we use lots of pictures of clothing and tell the computer what that's a picture of and then have the computer figure out the patterns that give you the difference between a shoe, and a shirt, and a handbag, and a coat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST Dataset\n",
    "The [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist) is a collection of grayscale 28x28 pixel clothing images.\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-4.PNG\" width=\"400\" alt=\"fashion-mnist\"><br>\n",
    "    <i>Image 1. Fashion Images Dataset</i>\n",
    "</p>\n",
    "\n",
    "For image resolution, the smaller the better it becomes because the computer has less processing to do. But of course, we need to retain enough information to be sure that the features and the object can still be distinguished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing code to load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# declare object, loading it from the keras database\n",
    "fashion_mnist = tf.keras.dataseets.fashion_mnist\n",
    "\n",
    "# (training data, training labels), (testing data, testing labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_minst.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 60,000 images for training the model and 10,000 left for testing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The structure of Fashion MNIST data\n",
    "\n",
    "The labels are represented by a number. Using a number is a first step in avoiding bias (instead of labelling it with words in a specific language).\n",
    "\n",
    "Learn more about how to avoid bias [here](https://ai.google/responsibilities/responsible-ai-practices/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding a Computer Vision Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # img resolution 28 x 28\n",
    "    # turns in into a simple linear array\n",
    "    keras.layers.Flattern(input_shape=(28,28)),\n",
    "\n",
    "    # hidden layer\n",
    "\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\n",
    "    # units = 10, represents 10 classes of clothing\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-5.PNG\" width=\"400\" alt=\"fashion-mnist\"><br>\n",
    "    <i>Image 2. Neural Network Layers </i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks to control training\n",
    "\n",
    "When you’re done with that, the next thing to do is to explore callbacks. One of the things you can do with that is to train a neural network until it reaches a threshold you want, and then stop training. You’ll see that in the next video.\n",
    "\n",
    "How can I stop training when I reach a point that I want to be at? Training loop does support callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.4):\n",
    "            print(\"\\nLoss is low so canceling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the code will look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is your Callbacks function\n",
    "...\n",
    "\n",
    "# calling callbacks\n",
    "callbacks = myCallback()\n",
    "\n",
    "# here is the rest of uour code\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "# modification\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Datasets\n",
    "\n",
    "Find more `tf.keras.datasets` API [here](https://www.tensorflow.org/api_docs/python/tf/keras/datasets).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
