{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. sequence models\n",
    "2. time series data\n",
    "3. how machine learning added here\n",
    "4. common patterns: trends, seasonality, upwards trend, autocorrelation, forecast learned patterns, non stationary time series, trend + seasonality + noise, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences and Prediction\n",
    "\n",
    "Take a look at some of the unique considerations involved when handling sequential time series data -- where values change over time, like the temperature on a particular day, or the number of visitors to your web site. We'll discuss various methodologies for predicting future values in these time series, building on what you've learned in previous courses!\n",
    "\n",
    "## Introduction\n",
    "Time-series is one part of sequence models where it's a case of if you can imagine a series of data that changes over time. It might be the closing prices for stock on the stock exchange, or it could be weather. It could be how sunny it is in California on a given day, or how rainy it is in Seattle on a given day, that type of thing. So if you just imagine how an item of data changes over time and how it's measured over time.\n",
    "\n",
    "We're going to start by creating a synthetic sequence of data, so that we can start looking at what the common attributes that you see in data series are. So for example:\n",
    "* Data can be seasonal. It's sunnier in June than it is in January or it's wetter in November than it is in October, something along those lines. So you have that seasonality of data. \n",
    "* Data can have trends, like whether it probably doesn't really trend although we could argue that it strangely enough idea with climate change, but like a stock data may trend upwards over time or downwards over some other times, and then of course the random factor that makes it hard to predict is noise. \n",
    "\n",
    "So you can have like seasonal data, you can have trends in your data, but then you can have noise on that data as well.\n",
    "\n",
    "## Time Series Example\n",
    "Different type of time series, looking at basic forecasting around them. Time series are everywhere. You may have seen them in stock prices, weather forecasts, historical trends, such as Moore's law. What exactly is a time series? It's typically defined as an ordered sequence of values that are usually equally spaced over time. So for example, every year in my Moore's law charts or every day in the weather forecast. \n",
    "\n",
    "In each of these examples, there is a single value at each time step, and as a results, the term **univariate** is used to describe them. You may also encounter time series that have multiple values at each time step. As you might expect, they're called **Multivariate Time Series**. \n",
    "\n",
    "Multivariate Time Series charts can be useful ways of understanding the impact of related data. For example, consider this chart of births versus deaths in Japan from 1950 to 2008. It clearly shows the two converging, but then deaths begin to outstrip births leading to a population decline. Now, while they could be treated as two separate univariate time series, the real value of the data becomes apparent when we show them together as a multivariate. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img\\birth-and-date.PNG\" alt=\"sequences\" width=500>\n",
    "</p>\n",
    "\n",
    "## Machine learning applied to time series\n",
    "What can we do?\n",
    "1. Forecasting based on the data, example: the birth and death rate chart for Japan. It would be very useful to predict future values so that government agencies can plan for retirement, immigration and other societal impacts of these trends.\n",
    "2. Detect anomalies. For example, in website logs so that you could see potential denial of service attacks showing up as a spike on the time series like this.\n",
    "3. Analyze the time series to spot patterns in them that determine what generated the series itself. A classic example of this is to analyze sound waves to spot words in them which can be used as a neural network for speech recognition.\n",
    "\n",
    "## Common patterns in time series\n",
    "Time-series come in all shapes and sizes, but there are a number of very common patterns. \n",
    "1. Trend, where time series have a specific direction that they're moving in. The general tendency of the values to go up or down as time progresses. \n",
    "2. Seasonality, which is seen when patterns repeat at predictable intervals. For instance, the hourly temperature might oscillate similarly for 10 consecutive days and you can use that to predict the behavior on the next day.\n",
    "3. Auto correlation, measurements at a given time step is a function of previous time steps\n",
    "4. Noise, not predictable at all and just a complete set of random values producing what's typically called white noise\n",
    "5. Non-stationary, break an expected pattern. Big events can alter the trend or seasonal behavior of the data, later its behavior does not change over time\n",
    "\n",
    "We always assume that more data is better. But for **time series forecasting it really depends on the time series**. If it's stationary, meaning its behavior does not change over time, then great. The more data you have the better. But if it's not stationary then the optimal time window that you should use for training will vary. Ideally, we would like to be able to take the whole series into account and generate a prediction for what might happen next.\n",
    "\n",
    "## Train, validation and test sets\n",
    "**Naïve forecasting** is the technique in which the last period's sales are used for the next period's forecast without predictions or adjusting the factors.\n",
    "\n",
    "### **How Do We Measure Performance?**\n",
    "To measure the performance of our forecasting model,. We typically want to split the time series into a training period, a validation period and a test period — **fixed partitioning.** \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img\\fixed-partitioning.PNG\" alt=\"fixed-partitioning\" width=500>\n",
    "</p>\n",
    "\n",
    "We'll train the model on the training period, and we'll evaluate it on the validation period. And work in it and the hyperparameter, until we get the desired performance, measured using the validation set. Then, test on test period to see if the model will perform just as well. \n",
    "\n",
    "There is also another way to split training, validation and test sets with using **roll-forward partitioning.** \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img\\roll-forward-partitioning.PNG\" alt=\"roll-forward-partitioning\" width=500>\n",
    "</p>\n",
    "\n",
    "## Metrics for Evaluating Performance\n",
    "Metrics used to calculate model performance. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img\\metrics.PNG\" alt=\"metrics\" width=500>\n",
    "</p>\n",
    "\n",
    "* Mean squared error (mse), square the errors and calculate their mean. It need to be squared because to get rid of negative values. \n",
    "* Square root, if we want the mean of our errors' calculation to be of the same as the original errors. \n",
    "* Mean absolute deviation (mae), instead of squaring to get rid of negatives we just uses their absolute value. \n",
    "* Mean absolute percentafe error (mape), the mean ratio between the absolute error and the absolute valuie. This give an idea of the size of the errors compared to the values. \n",
    "\n",
    "### When to Use MSE and MAE?\n",
    "If large errors are potentially dangerous and they cost you much more than smaller errors, then you may prefer the mse. But if your gain or your loss is just proportional to the size of the error, then the mae may be better.\n",
    "\n",
    "```python\n",
    "# Naive Forecast MAE\n",
    "keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy()\n",
    "```\n",
    "\n",
    "## References\n",
    "* [Ungraded Lab - C4_W1_Lab_1_time_series](https://colab.research.google.com/drive/1_QdTh3jQxxAMCekxUbagkmL-mJKDUSom?usp=sharing)\n",
    "* [Ungraded Lab - C4_W1_Lab_2_forecasting](https://colab.research.google.com/drive/1MlZKLUVBQVLEvfPzeadeDMg7j8q11ozW?usp=sharing)\n",
    "* [Naïve Forecasting](https://www.avercast.in/blog/what-is-naive-forecasting-and-how-can-be-used-to-calculate-future-demand#:~:text=Na%C3%AFve%20forecasting%20is%20the%20technique,to%20the%20final%20observed%20value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks for Time Series\n",
    "\n",
    "Recurrent Neural networks (RNN) and Long Short Term Memory (LSTM) networks are really useful to classify and predict on sequential data. \n",
    "\n",
    "### Sequence Data\n",
    "Sequential Data is any kind of data where the order matters as you said. So we can assume that time series is a kind of sequential data, because the order matters.\n",
    "\n",
    "### Sequence Model\n",
    "Sequence models are the machine learning models that input or output sequences of data. Sequential data includes text streams, audio clips, video clips, time-series data and etc.\n",
    "\n",
    "### Lambda Layers\n",
    "Lambda layers allow us to write effectively an arbitrary piece of code as a layer in the neural network. Basically a Lambda function, an unnamed function, but implemented as a layer in the neural network that resend the data, scales it. More simply we can say that using the lambda layer we can transform the data before applying that data to any of the existing layers.\n",
    "\n",
    "## Conceptual Overview\n",
    "One difference will be that the full input shape when using RNNs is three-dimensional. The first dimension will be the batch size, the second will be the timestamps, and the third is the dimensionality of the inputs at each time step. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img\\recurrent-layer.PNG\" alt=\"metrics\" width=500>\n",
    "</p>\n",
    "\n",
    "What it looks like there's lots of cells, there's actually only one, and it's used repeatedly to compute the outputs. This is what gives this type of architecture the name a recurrent neural network, because the values recur due to the output of the cell, a one-step being fed back into itself at the next time step.\n",
    "\n",
    "## When to Use RNN and LSTM\n",
    "RNNs are particularly suited for tasks that involve sequences (thanks to the recurrent connections). For example, they are often used for machine translation, where the sequences are sentences or words. In practice, an LSTM is often used, as opposed to a vanilla (or standard) RNN, because it is more computationally effective. In fact, the LSTM was introduced to solve a problem that standard RNNs suffer from, i.e. the vanishing gradient problem. (Now, for these tasks, there are also the transformers, but the question was not about them).\n",
    "\n",
    "## References\n",
    "* [Sequence Models & Recurrent Neural Networks](https://towardsdatascience.com/sequence-models-and-recurrent-neural-networks-rnns-62cadeb4f1e1#:~:text=Sequence%20models%20are%20the%20machine,algorithm%20used%20in%20sequence%20models.&text=1.)\n",
    "* [Introduction to Sequence Modeling Problems](https://towardsdatascience.com/introduction-to-sequence-modeling-problems-665817b7e583)\n",
    "* [Ungraded Lab: Using a Simple RNN for forecasting](https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/main/C4/W3/ungraded_labs/C4_W3_Lab_1_RNN.ipynb)\n",
    "* [Ungraded Lab: Using a multi-layer LSTM for forecasting](https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/main/C4/W3/ungraded_labs/C4_W3_Lab_2_LSTM.ipynb)\n",
    "* [Huber Loss](https://en.wikipedia.org/wiki/Huber_loss)\n",
    "* [LSTM Lesson](https://www.coursera.org/lecture/nlp-sequence-models/long-short-term-memory-lstm-KXoay)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
