{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this Course\n",
    "This course is part of the upcoming Machine Learning in Tensorflow Specialization and will teach you best practices for using TensorFlow, a popular open-source framework for machine learning. \n",
    "\n",
    "The Machine Learning course and Deep Learning Specialization from Andrew Ng teach the most important and foundational principles of Machine Learning and Deep Learning. This new deeplearning.ai TensorFlow Specialization teaches you how to use TensorFlow to implement those principles so that you can start building and applying scalable models to real-world problems. To develop a deeper understanding of how neural networks work, we recommend that you take the Deep Learning Specialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllabus\n",
    "* Week 01: A New Programming Paradigm\n",
    "* Week 02: Introduction to Computer Vision\n",
    "* Week 03: Enhancing Vision with Convolutional Neural Networks\n",
    "* Week 04: Using Real-world Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A New Programming Paradigm\n",
    "\n",
    "## An Overview\n",
    "* One of the best tools we can use to implement deep learning and machine learning algorithms is TensorFlow.\n",
    "* Programming frameworks like TensorFlow, PyTorchm caffe and many others can help us in learning algorithms, moreover they can save a lot of time.\n",
    "* Deep learning and machine learning skills are becoming ever more important and opening up whole new scenarios.\n",
    "* Even though the whole world sees the promise and the hope of these machine learning AI capabilities changing so many things, the world just doesn't have enough AI developers today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Primer in Machine Learning\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-1.PNG\" alt=\"traditional-programming\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 1. Traditional Programming</i></p>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-3.PNG\" alt=\"activity-recognition\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 2. Activity Recognition using Traditional Programming</i></p>\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-2.PNG\" alt=\"new-programming\" width=\"400\"/>\n",
    "</p>\n",
    "<p align=\"center\"><i>Image 3. New Programming</i></p>\n",
    "\n",
    "* Rules are express in a programming language and data can come from a variety of sources from local variables or the way up to databases\n",
    "* Machine learning is really similar but we only flipping the axes\n",
    "* Neural network is the workhorse of doing this type of pattern recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ‘Hello World’ of neural networks\n",
    "Machine learning is all about a computer learning the patterns that distinguish things. The simplest possible neural network is one that has only one neuron in it, we can see it the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In keras, we use Dense to define a layer of connected neurons\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) \n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype-float)\n",
    "\n",
    "# the training takes place in the fit command\n",
    "# epoch = 500, means that it will go through the training loop 500 times\n",
    "model.fit(xs, ys, epochs=500)\n",
    "\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions, **loss** and **optimizer**. \n",
    "* Loss function measure how good or how bad its guess was. Loss function is mean squarred error.\n",
    "* Optimizer function figures out the next guess, how good or how badly the guess was done using the data from the loss function. Each guess should be better than the one before. Optimizer is SGD (Stochastic Gradient Descent)\n",
    "\n",
    "In conclusion, the steps to figure out the patterns are:\n",
    "1. Make a guess\n",
    "2. Measure how good or how bad the guesses with the loss function\n",
    "3. Use the optimizer and the data to make another guess and repeat this\n",
    "\n",
    "If the result is far from expectation or what you guess before, there are 2 reasons for it.\n",
    "1. Training data is too small\n",
    "2. When using neural networks, they deal in probability as they try to figure out the answers for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Rules to Data\n",
    "* Traditional paradigm of expressing rules in a coding language may not always work to solve a problem. Computer vision are very difficult to solve with rules-based programming.\n",
    "* We can feed a computer with enough data that we describe / label as what we want it to recognize. Example: fitting numbers to a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "\n",
    "Computer vision is the field of having a computer understand and label what is present in an image. Can you figure out how can we tell the computer to recognize fashion image? Yes, we use lots of pictures of clothing and tell the computer what that's a picture of and then have the computer figure out the patterns that give you the difference between a shoe, and a shirt, and a handbag, and a coat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST Dataset\n",
    "The [Fashion MNIST Dataset](https://github.com/zalandoresearch/fashion-mnist) is a collection of grayscale 28x28 pixel clothing images.\n",
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-4.PNG\" width=\"400\" alt=\"fashion-mnist\"><br>\n",
    "    <i>Image 1. Fashion Images Dataset</i>\n",
    "</p>\n",
    "\n",
    "For image resolution, the smaller the better it becomes because the computer has less processing to do. But of course, we need to retain enough information to be sure that the features and the object can still be distinguished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing code to load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# declare object, loading it from the keras database\n",
    "fashion_mnist = tf.keras.dataseets.fashion_mnist\n",
    "\n",
    "# (training data, training labels), (testing data, testing labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_minst.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 60,000 images for training the model and 10,000 left for testing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The structure of Fashion MNIST data\n",
    "\n",
    "The labels are represented by a number. Using a number is a first step in avoiding bias (instead of labelling it with words in a specific language).\n",
    "\n",
    "Learn more about how to avoid bias [here](https://ai.google/responsibilities/responsible-ai-practices/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding a Computer Vision Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # img resolution 28 x 28\n",
    "    # turns in into a simple linear array\n",
    "    keras.layers.Flattern(input_shape=(28,28)),\n",
    "\n",
    "    # hidden layer\n",
    "\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\n",
    "    # units = 10, represents 10 classes of clothing\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"img/capture-5.PNG\" width=\"400\" alt=\"fashion-mnist\"><br>\n",
    "    <i>Image 2. Neural Network Layers </i>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks to control training\n",
    "\n",
    "When you’re done with that, the next thing to do is to explore callbacks. One of the things you can do with that is to train a neural network until it reaches a threshold you want, and then stop training. You’ll see that in the next video.\n",
    "\n",
    "How can I stop training when I reach a point that I want to be at? Training loop does support callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks function.\n",
    "```python\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.4):\n",
    "            print(\"\\nLoss is low so canceling training!\")\n",
    "            self.model.stop_training = True\n",
    "```\n",
    "\n",
    "Then the code will look like this.\n",
    "```python\n",
    "# here is your Callbacks function\n",
    "...\n",
    "\n",
    "# calling callbacks\n",
    "callbacks = myCallback()\n",
    "\n",
    "# here is the rest of uour code\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "# modification\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Other Datasets\n",
    "\n",
    "Find more `tf.keras.datasets` API [here](https://www.tensorflow.org/api_docs/python/tf/keras/datasets).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Vision with Convolutional Neural Networks\n",
    "\n",
    "## What are convolutions and pooling?\n",
    "* Some convolutions will change the image in such a way that certain features in the image get emphasized\n",
    "*  Pooling is a way of compressing an image\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.Sequential([\n",
    "    # input layer in the shape of our data\n",
    "    tf.keras.layers.Flatten(), # input_shape=(28,28)\n",
    "    # hidden layer\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    # output layer in the shape of the number categories\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "```\n",
    "\n",
    "## Implementing convolutional layers\n",
    "\n",
    "```python\n",
    "model = tf.keras..models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "### Conv2D\n",
    "```python\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1))\n",
    "```\n",
    "\n",
    "### MaxPooling2D\n",
    "```python\n",
    "tf.keras.layers.MaxPooling2D(2,2)\n",
    "```\n",
    "\n",
    "* In max-pooling, we're going to take the maximum value\n",
    "* It's a two-by-two pool, so for every four pixels, the biggest one will **survive** \n",
    "\n",
    "Then, we add another convolutional later and another max-pooling layer and then again, pool to reduce the size. So, by the time the image gets to the flattern to go into the dense layers, it's already **much smaller**.\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "```\n",
    "\n",
    "So, its content has been greatly simplified, the goal being that the convolutions will filter it to the features that determine the output.\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "## Other Notes\n",
    "**Overfitting** occurs when the network learns the data from the training set really well, but it's too specialised to only that data, and as a result is less effective at interpreting other unseen data. For example, if all your life you only saw red shoes, then when you see a red shoe you would be very good at identifying it. But blue suede shoes might confuse you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Real-world Images\n",
    "\n",
    "## Understanding ImageDataGenerator\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tf.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# instantiate an image generator\n",
    "# pass rescale to normalize the data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# point out directory that contains sub-directories that contain images\n",
    "# the name of sub-directories will be the labels for the images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(300, 300), # input data all has to be the same size\n",
    "    batch_size=128,\n",
    "    class_mode='binary' # binary classifier\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "```\n",
    "\n",
    "* The images are resized as they are loaded so we don't need to do preprocessing\n",
    "* Batch size is a term used in machine learning and refers to the number of training examples utilized in one iteration.\n",
    "\n",
    "## Defining a ConvNet to use complex images\n",
    "Here, we use three sets of convolution pooling layers.\n",
    "```python\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "```\n",
    "\n",
    "In input shape, because the images are in color we use 3 bytes per pixel for red, green and blue.\n",
    "```python\n",
    "tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
    "```\n",
    "\n",
    "For the output layer, we have one neuron for two classes. It because we use different activation. Sigmoid is great for binary classification, where one class will tend towards zero and the other class tending towards one. We could use two neurons here too, and the same softmax function as before, but for binary this is a bit more efficient. \n",
    "```python\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "```\n",
    "\n",
    "## Training The ConvNet\n",
    "```python\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(lr=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=8,\n",
    "    verbose=2\n",
    ")\n",
    "```\n",
    "\n",
    "* There are 1,024 images in the training directory, we're loading them in 128 at a time. In order to load them all, we need to do 8 batches so we set **steps_per_epoch** to cover that.\n",
    "* We have 256 images from validation_genertaor and we wanted to handle them in batches of 32, so we will do 8 steps.\n",
    "* Verbose specifies how much to display while training is going on. With verbose set to 2, we'll get a little less animation hiding the epoch progress.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a human\")\n",
    "    else:\n",
    "        print(fn + \" is a horse\")\n",
    "```\n",
    "\n",
    "This give us the button that can be pressed to pick one or more images to upload.\n",
    "```python\n",
    "...\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "    ...\n",
    "    ...\n",
    "```\n",
    "\n",
    "The loop then iterates through all of the images in that collection.\n",
    "```python\n",
    " img = image.load_img(path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
